{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Melody Generation\n",
    "\n",
    "+ **AI in Culture and Arts - Tech Crash Course**\n",
    "+ **Date:** 06.06.2024\n",
    "+ **Author:** B. ZÃ¶nnchen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/aica-wavelab/aica-assignments/blob/main/A4_melody_generation/3_2_melody_representations.ipynb\" target=\"_parent\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following we will create music sheets and sound. For those tasks ``Python`` requires external programs that you should install if you are working locally:\n",
    "\n",
    "1. [Musescore](https://musescore.org/de) (for generating sheets)\n",
    "2. [FluidSynth](https://www.fluidsynth.org/) (for generating sound)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are working on google ``Colab``, you can evaluate the following to cells to install these applications:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title install dependencies to play sound\n",
    "%%capture\n",
    "print('installing fluidsynth...')\n",
    "!apt-get install fluidsynth > /dev/null\n",
    "!cp /usr/share/sounds/sf2/FluidR3_GM.sf2 ./font.sf2\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title install dependencies to show score in music notation\n",
    "%%capture\n",
    "print('installing musescore3...')\n",
    "!apt-get install musescore3 > /dev/null\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title clone git repository\n",
    "%%capture\n",
    "%rm -rf aica-assignments\n",
    "!git clone https://github.com/aica-wavelab/aica-assignments.git\n",
    "%cd aica-assignments/A4_melody_generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furtheremore, for this notebook we need the following ``Python`` packages and moduls. Execute the cell to install them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install music21\n",
    "%pip install pyfluidsynth\n",
    "\n",
    "%pip install pandas\n",
    "%pip install numpy\n",
    "%pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"3_2_melody_representations.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import music21 as m21\n",
    "from music21.note import Note\n",
    "from music21.stream import Stream\n",
    "\n",
    "# import functions\n",
    "from pianoroll import stream_to_df, has_acceptable_duration, plot_df\n",
    "from files import load_midi_files\n",
    "from encoder import PianoRollEncoder, StringToIntEncoder\n",
    "\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2 Representing Melodies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case of a melody we can choose a special kind of representation since we know that there is no verticality, that is, the problem becomes one dimensional like text! In this section we talk more about representations, a topic which might sound boring but which is more important than you might think!\n",
    "\n",
    "The ``.zip`` file ``data/deu_folk_songs.zip`` contains MIDI files of melodies.\n",
    "These files represent our **training data** for our *deep learning* attempts later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile('data/deu_folk_songs.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('data/deu_folk_songs/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us unzip it. Then you can use the ``load_midi_files`` function to load all the MIDI files. It returns a list of ``Stream`` objects.\n",
    "You can control how many files you want to load at max. using the ``max_file`` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streams_folk_songs = load_midi_files('data/deu_folk_songs/', max_files=10) # load only 10 files\n",
    "print(f'load {len(streams_folk_songs)} files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streams_folk_songs[0].show('midi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streams_folk_songs[0].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Note-Based Representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first straightforward representation that also works for polyphonic music is to use three numbers for each ``Note`` where ``Chord``s can be broken down into ``Note``s:\n",
    "\n",
    "1. ``pitch``: The pitch of the note (in MIDI)\n",
    "2. ``duration``: The duration in quarters of the note\n",
    "3. ``step``: The time elapsed from the previous note or beginning of the track\n",
    "\n",
    "We need ``step`` to be able to represent ``Rest``s!\n",
    "\n",
    "We prepared a function ``stream_to_df`` that transforms a ``Stream`` object into a ``panda`` ``DataFrame`` follows this approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick a folk song\n",
    "stream = streams_folk_songs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = stream_to_df(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``pitch`` is the MIDI note that is played over a duration of ``duration``. The note starts at ``start`` and ends at ``end = start + duration``. The step is the time elapsed from the previous note or start of the track. ``Rest``s have no explicit entry. The rows of the ``DataFrame`` are sorted by ``start``.\n",
    "\n",
    "If the ``DataFrame`` is ordered according to start, we have all the information required by only selecting ``pitch``, ``duration``, and ``step`` use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe[['pitch', 'duration', 'step']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``dataframe`` can also be displayed like a **piano roll** using ``plot_df``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df(dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This representation also works for polyphonic pieces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a polyphonic score from a midi file\n",
    "minuet_in_G = m21.converter.parse('data/Minuet_in_G.mid')\n",
    "\n",
    "# convert it into a DataFrame\n",
    "minuet_df = stream_to_df(minuet_in_G)\n",
    "minuet_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df(minuet_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 Piano Roll-Based Representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we looked at the **classical notation of Western music**. The **piano roll** is another representation of a score often used in digital audio workstations (DAWs). Above, we already saw a visualization of it. Since it is far more regular than the classical notation, it is often easier to be analysed by the computer.\n",
    "\n",
    "A *piano roll* is basically a two-dimensional grid where the $x$-axes represents time which is **discretized into fixed time steps** and the $y$-axes represents the MIDI note number.\n",
    "The value for one specific cell in the grid is ``1`` **if and only if** the MIDI note will be played at that time.\n",
    "Otherwise the value is ``0``.\n",
    "\n",
    "Time is discretized into small but equally large chunks called **time steps**. Because of this discretization, we cannot represent arbitrary durations of a note!\n",
    "This simplifies the problem but also limits the expressiveness of the musical piece we can represent.\n",
    "In our case, a time step is defined in multiples of quarter notes (we stick to the convention of ``music21``).\n",
    "For example, if the ``time_step = 1.0`` meaning it represents the duration of one quarter note, then we can only represent durations that are multiples of a quarter note, that is:\n",
    "\n",
    "```\n",
    "1/4, 2/4, 3/4, 4/4, 5/4, ...\n",
    "```\n",
    "\n",
    "We cannot, for example, represent a duration of ``3/5``!\n",
    "Therefore, if you are working with a piano roll like representation, you might want to filter your (training) data accordingly.\n",
    "For this reason you can use ``has_acceptable_duration(stream, time_step)`` to test if the ``Stream`` can be represented by a piano roll using a time step equal to ``time_step``.\n",
    "\n",
    "Futhermore, the function ``load_midi_files`` offers a parameter ``time_step`` to filter for ``Score``s compatible with a certain ``time_step`` in quarters. Internally, it uses the ``has_acceptable_duration()`` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_step = 0.5 # which is effectively one eighth note\n",
    "streams_folk_songs = load_midi_files('data/deu_folk_songs/', time_step=time_step, max_files=10) # load only 10 files\n",
    "print(f'load {len(streams_folk_songs)} files that are compatible with a time step of {time_step}')\n",
    "has_acceptable_duration(streams_folk_songs[0], time_step=time_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If one looks into the research literature, one can find representations that are based on the piano roll representation to train a deep neural network that is able to generate symbolic scores. However, to capture fine-grained dynamics in a performance, these models rely on a tiny ``time_step`` which would lead to massive amount of data. Imagine we would use a time step equal to 0.01 quarters and our piece is 100 quarters long. To represent this piece would mean to generate a sequence of length equal to $100 / 0.01 = 10000$!\n",
    "\n",
    "To counteract this problem, they include special **events** to skip forward in time! These events are categorical thus they also rely on a *one-hot encoding*. If you are interested in this idea, here is one of the first papers discussing this approach: [This Time with Feeling: Learning Expressive Musical Performance](https://arxiv.org/abs/1808.03715)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Instruction 3.2.1** Generate a ``Stream`` called ``stream`` such that ``has_acceptable_duration`` returns ``False`` for a ``time_step`` equal to ``1.0`` but returns ``True`` for a ``time_step`` equal to ``0.5``.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stream = Stream()\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Instruction 3.2.2**: In the follwoing we are interested in melodies (no ``Chord``s and only one ``Part``). What might be a good representation for melodies that is similarily regular than the piano roll representation but is one-dimensional?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "To convert a ``Stream`` to a one-dimensional piano roll representation, you can use the ``PianoRollEncoder``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us get two example streams\n",
    "melody1 = streams_folk_songs[0]\n",
    "melody2 = streams_folk_songs[1]\n",
    "\n",
    "# Convert streams to piano roll DataFrame\n",
    "time_step = 0.5\n",
    "streams = [melody1, melody2]\n",
    "print(f'1.0 quarter note is acceptable for stream1: {has_acceptable_duration(melody1, time_step=time_step)}')\n",
    "print(f'1.0 quarter note is acceptable for stream2: {has_acceptable_duration(melody2, time_step=time_step)}')\n",
    "\n",
    "piano_roll_encoder = PianoRollEncoder(time_step=time_step)\n",
    "enc_streams, invalid_streams = piano_roll_encoder.encode_streams([melody1,melody2])\n",
    "\n",
    "print(enc_streams[0])\n",
    "print(enc_streams[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Instruction 3.2.3**: Can you figure out the meaning of the different symbols? What does e.g. \n",
    "\n",
    "```'70', '_', '_', '65', '62', '_', '65', '_', ...```\n",
    "\n",
    "mean ?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Instruction 3.2.4**: Compare the resulting ``enc_streams`` with their respective ``Stream`` by using ``.show()``.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a nice list of characters in a piano roll like format. However, as we already explained in *3_1_one_hot_encoding*, it is preferable to convert everything into numbers ranging from $0$ to $m-1$ to be able (if desirable) to generate a *one-hot encoding*. We can do this by using the ``StringToIntEncoder``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = StringToIntEncoder(enc_streams)\n",
    "\n",
    "melody1_enc = encoder.encode_sequence(enc_streams[0])\n",
    "print(enc_streams[0])\n",
    "print(melody1_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melody2_enc =  encoder.encode_sequence(enc_streams[1])\n",
    "print(enc_streams[1])\n",
    "print(melody2_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melody1_dec = encoder.decode_sequence(melody1_enc)\n",
    "print(melody1_dec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Instruction 3.2.5**: The variable ``streams_folk_songs`` contains 10 ``Stream`` objects which where generated from 10 different ``mid``-files.\n",
    "\n",
    "1. Generate a piano roll plot for at least 2 of those ``Stream``s (use ``plot_df``)\n",
    "2. Generate a list ``piano_rolls`` containing all encoded ``Stream``s using ``PianoRollEncoder``\n",
    "3. Generate a list ``enc_piano_rolls`` containing all encoded ``Stream``s using ``StringToIntEncoder``\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# (1)\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# (1)\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# (2)\n",
    "piano_roll_encoder = ...\n",
    "piano_rolls, _ = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stoi_encoder = ...\n",
    "enc_piano_rolls = ...\n",
    "print(enc_piano_rolls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q35\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "otter": {
   "assignment_name": "3_2_melody_representations"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
