{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and email below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full name\n",
    "NAME = \"\"\n",
    "# Institutional email (hm.edu or hmtm.de)\n",
    "EMAIL = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ce5e4b6c2d1dafebbc3cee5aa4465b4b",
     "grade": false,
     "grade_id": "cell-474a1bc560903e74",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Rudiments of machine learning\n",
    "\n",
    "This notebook is a brief introduction to machine learning. It is intended for beginners who are interested in predictive modelling and machine learning. The notebook covers the different steps of the development of a machine learning model, and provides a concrete application: **Museum visitors prediction in the city of Bristol, UK**.\n",
    "\n",
    "\n",
    "<image src=\"https://live.staticflickr.com/1571/25139082514_36dcf31ae0_b.jpg\" width=\"400px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "35fcd57b52d2ce8a484e48159f74b374",
     "grade": false,
     "grade_id": "cell-a06d1ef05498bcf7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We possess two datasets that comprise daily information from April 2014 to February 2019:\n",
    "\n",
    "- `bristol_museum_visit.csv` contains the daily number of visitors for the museums of Bristol.\n",
    "- `bristol_weather.csv` contains the daily weather information in Bristol on the same time period: the temperature mean, the temperature range, the sum of precipitation, the sum of snowfall, and the max wind speed.\n",
    "\n",
    "Our goal is simple: we want to train machine learning model that predict the number of visitor from on all available information (museum name, day of the week, month, weather etc.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6ee84af88fc3c67a4a60ae7e8a0a0286",
     "grade": false,
     "grade_id": "cell-ed36f7f54ace0443",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The development of a machine learning model can be divided into several steps. The most common steps include:\n",
    "\n",
    "1. Data collection\n",
    "2. Data preprocessing and feature selection\n",
    "3. Model selection\n",
    "4. Model training\n",
    "5. Model evaluation\n",
    "6. Model deployment\n",
    "\n",
    "Rather than steps, these can be seen as a cycle, as a problem in one step can lead to revisiting a previous step. In this notebook, we will go through these steps in order to build a predictive model for the number of visitors in Bristol museums."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dc8b518b1655ff4f05114c73ea5f499d",
     "grade": false,
     "grade_id": "cell-1c097cb15c08c098",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1. Data collection\n",
    "\n",
    "### 1.1 Daily museum visitors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "677ccb8aa3a2c3d54843ff2bb0153327",
     "grade": false,
     "grade_id": "cell-b0ed605abe95de2e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "museum_visits = pd.read_csv('data/bristol_museum_visit.csv')\n",
    "museum_visits[\"date\"] = pd.to_datetime(museum_visits[\"date\"])\n",
    "museum_visits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e9e998a1b2f77fe45a48ac1421348f64",
     "grade": false,
     "grade_id": "cell-b426e77f8a2c16a7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>Instruction:</b> How many unique museums are in the dataset?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5426aaa4fa6076277416d3fa6d3f88a9",
     "grade": true,
     "grade_id": "cell-6fc98d412783ac94",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cf7ec8c401bcccf53f5201aec8b50434",
     "grade": false,
     "grade_id": "cell-cd5ac9b63a7f6236",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>Instruction:</b> What is the time range of the dataset?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f1c8c608b10c1ec0ad970fd5713d217f",
     "grade": true,
     "grade_id": "cell-81c969023718a992",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "029f6b95304c376de9e89bcd87582c00",
     "grade": false,
     "grade_id": "cell-8b04b9c0e6bea389",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>Instruction:</b> Plot the number of visitors for each museum as a function of time and limited to the year 2018. Visualize each museum in a different color.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c60910827f9306ce9650cc6ce245781b",
     "grade": true,
     "grade_id": "cell-8457461e68033990",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "visitors2018 = museum_visits[museum_visits[\"date\"].dt.year == 2018]\n",
    "plt.figure(figsize=(15, 5))\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bdbeb4e91259c7146439ed4c2a876157",
     "grade": true,
     "grade_id": "cell-c6ab3a6d09b908ce",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>Instruction:</b> Describe the visualization. What can you say about the number of visitors in 2018?\n",
    "</div>\n",
    "\n",
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "93d7d1f2b8b44b689db8b163dae3f433",
     "grade": false,
     "grade_id": "cell-9aace8550d290d64",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.2 Daily weather information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b29b1c0fb1c70cdae665b5709b190c17",
     "grade": false,
     "grade_id": "cell-a6b08b507286fffe",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "weather = pd.read_csv('data/bristol_weather.csv')\n",
    "weather[\"date\"] = pd.to_datetime(weather[\"date\"])\n",
    "weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2fef473eed1381c2b8cb53a9920a6582",
     "grade": false,
     "grade_id": "cell-b00c79dc79a06d0c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>Instruction:</b> Plot each weather feature as a function of time and limited to the year 2018. Visualize each weather feature in a different color.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "03f8240db88eeb80089805eeb8a261a5",
     "grade": false,
     "grade_id": "cell-89a05848beb96038",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Warning:</b> Seaborn requires the data to be in a specific format called \"long-form\" or \"tidy data\". \n",
    "\n",
    "In this format, each row is an observation and each column is a variable. You can use the `melt` method to convert the data to this format.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2c6589830206a34d9ec68fbbaccc3805",
     "grade": false,
     "grade_id": "cell-747802ac3bc84a48",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "weather2018 = weather[weather[\"date\"].dt.year == 2018]\n",
    "plt.figure(figsize=(15, 5))\n",
    "# Melt all features except the date column\n",
    "weather2018_melted = weather2018.melt(id_vars=[\"date\"], value_vars=weather2018.columns[1:], var_name=\"weather_feature\", value_name=\"value\")\n",
    "weather2018_melted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "755bd59913b91f4e59700b4d5e110d31",
     "grade": true,
     "grade_id": "cell-89369e907da481ad",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8b7f013f7269a4d117f1ca1a917880ed",
     "grade": true,
     "grade_id": "cell-76376dc4b0834237",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>Instruction:</b> Describe the visualization. What kind of variations and periodicity do you observe in the weather features?\n",
    "</div>\n",
    "\n",
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f59cb518abd86a8b375de6fcafe777aa",
     "grade": false,
     "grade_id": "cell-8c9b5d0d25bd5399",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# 1.2 Data preprocessing and feature selection\n",
    "\n",
    "Now we collected our two dataset, we need to preprocess them before we can use them to train a machine learning model. The preprocessing steps include:\n",
    "\n",
    "- Merging of all relevant features\n",
    "- Handling missing values\n",
    "- Encoding categorical features into numerical values or one-hot encoding\n",
    "- Feature normalization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ba925734a010670e786efbc75a68582e",
     "grade": false,
     "grade_id": "cell-9005f8ee9091769f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.2.1 Merging all relevant features\n",
    "\n",
    "<div  class=\"alert alert-info\">\n",
    "<b>Instruction:</b> Use the `pd.merge` function to combine the two datasets based on the `date` column.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "739305a3b6d3f5e119d147e0b5a4266e",
     "grade": true,
     "grade_id": "cell-b7515767dd800bf5",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "573fb11caded12c6f17eb147d6b3b8d5",
     "grade": false,
     "grade_id": "cell-98774cc02c5c260f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.2.2 Handling missing values\n",
    "\n",
    "Let's check if there are any missing values in the dataset using the `isna` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e32ea313067d639ca5822b78d962d2f8",
     "grade": false,
     "grade_id": "cell-6d2457d8748e52a1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4971bcba7fa20ff0169decc13d882091",
     "grade": false,
     "grade_id": "cell-3a829d60c58b0f7e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We are lucky as there are no missing values in the dataset. However, in a real-world scenario, missing values are common and need to be handled. There are several strategies to handle missing values, including:\n",
    "\n",
    "- Removing the rows with missing values\n",
    "- Imputing the missing values with the mean, median, or mode of the column\n",
    "- Using machine learning algorithms that can handle missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ccea41012e8d32785fb69278f202e7f8",
     "grade": false,
     "grade_id": "cell-cf83ef2cf5e8ad3e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.2.3 Encoding categorical features into numerical values\n",
    "\n",
    "Our data comprise at least one categorical feature: the museum name. Machine learning algorithms require numerical input data, so we need to encode the categorical features into numerical values. \n",
    "\n",
    "The machine learning library `scikit-learn` we are going to use today provides a class called `LabelEncoder` to encode categorical features into numerical values.\n",
    "\n",
    "A good practice is to use one-hot encoding to encode categorical features. One-hot encoding creates a binary column for each category, with the column containing 1 if the category is present and 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0221a77e60a9463a2d818ad6c27ac411",
     "grade": false,
     "grade_id": "cell-c524beffdfc7f0a6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell if you have not installed scikit-learn or work on a Google Colab notebook\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fb1b1a35965ad1a048548bd0c899129c",
     "grade": false,
     "grade_id": "cell-1f9d54f24bab9c0d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "data_encoded = pd.get_dummies(data, columns=[\"museum\"], prefix=\"museum\")\n",
    "data_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "005a6d7ff730f3f7455f69aa0748e532",
     "grade": false,
     "grade_id": "cell-89f5e582451014bb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The date format might not be useful for our predictive model as it is. A more useful feature would be to extract the day of the week and the month from the date.\n",
    "\n",
    "These new features are also **categorical** and need to be encoded as one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9a2a7754a49f0e76c1c86f0fc215c698",
     "grade": false,
     "grade_id": "cell-a6aac17e581e1585",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Map day of the week and month from numbers to names\n",
    "data_encoded['day_of_week'] = data_encoded['date'].dt.dayofweek.map({\n",
    "    0: 'Monday', 1: 'Tuesday', 2: 'Wednesday', 3: 'Thursday', 4: 'Friday', 5: 'Saturday', 6: 'Sunday'\n",
    "})\n",
    "data_encoded['month'] = data_encoded['date'].dt.month.map({\n",
    "    1: 'January', 2: 'February', 3: 'March', 4: 'April', 5: 'May', 6: 'June',\n",
    "    7: 'July', 8: 'August', 9: 'September', 10: 'October', 11: 'November', 12: 'December'\n",
    "})\n",
    "\n",
    "# Create one-hot encoded features\n",
    "data_one_hot = pd.get_dummies(data_encoded, columns=['day_of_week', 'month'], prefix=['day', 'month'])\n",
    "\n",
    "# Display the new DataFrame with named one-hot encoded columns\n",
    "data_one_hot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "162ba3791a0405e3cd4bb84e35eabc86",
     "grade": false,
     "grade_id": "cell-0a8d5d9e8104c178",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "As public holidays can have an impact on the number of visitors, we can add a new feature that includes the number of the day in the month (1 to 31)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ed2537fa25eb188e028a6c047fc38b65",
     "grade": false,
     "grade_id": "cell-6a0b4cf4185a72aa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Add number of the day in the month as a feature\n",
    "data_one_hot['day'] = data_one_hot['date'].dt.day\n",
    "data_one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "da47c00fb901bbeb9cda08176112b8cc",
     "grade": false,
     "grade_id": "cell-e73a2f3e1d59df42",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We can now remove the `date` column from the dataset and move to our next step: **feature normalization**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3d1ce21323b7e2c5fe64528ea6a7f78f",
     "grade": false,
     "grade_id": "cell-4169c734df019fb6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "data_one_hot = data_one_hot.drop(columns=[\"date\"])\n",
    "data_one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "174301f1ab3a53393dbfa199d7ed138f",
     "grade": false,
     "grade_id": "cell-d394743fe0a8cc0b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.2.4 Feature normalization\n",
    "\n",
    "Feature normalization is an important step in data preprocessing and **only applies to ordinal features**, in our case, the weather features and the number of the day. Normalizing the ordinal data ensures that each feature contributes approximately proportionately to the final prediction.\n",
    "\n",
    "Several normalization techniques exist, including:\n",
    "\n",
    "- Min-max scaling: scales the data to a fixed range, usually [0, 1]\n",
    "- Z-score normalization: scales the data to have a mean of 0 and a standard deviation of 1\n",
    "- ...\n",
    "\n",
    "We decide to use the Min-max scaling technique to normalize the weather features and import the `MinMaxScaler` class from the `scikit-learn` library to do so.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "56ac96973bb25e387b85bfe0b0206b55",
     "grade": false,
     "grade_id": "cell-040639cd872e04f4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# min-max scaling of certain features\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "data_one_hot_scaled = data_one_hot.copy()\n",
    "# Normalize the weather features (5 first columns)\n",
    "data_one_hot_scaled[data_one_hot.columns[:5]] = scaler.fit_transform(data_one_hot[data_one_hot.columns[:5]])\n",
    "# Normalize the column \"day\"\n",
    "data_one_hot_scaled[\"day\"] = scaler.fit_transform(data_one_hot[[\"day\"]])\n",
    "data_one_hot_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bd6210de1114aa3f9659f376996278ed",
     "grade": false,
     "grade_id": "cell-19f9503f6fc7f9b1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "As a last step, let's move the output variable `daily_visitors` to the end of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "05b18196530e29779427c1fb3af15748",
     "grade": false,
     "grade_id": "cell-cec836d93b5f3048",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Move the daily_visitors column to the end\n",
    "data_processed = data_one_hot_scaled[[c for c in data_one_hot_scaled if c not in ['daily_visitors']] + ['daily_visitors']]\n",
    "data_processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "82b1dd95cf850acc5150db4e1a57b6c5",
     "grade": false,
     "grade_id": "cell-66bf786af2a3ee9f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We have now preprocessed our data to be used in a machine learning model. Before moving to the next step, we can develop our intuition about the most important features to predict the daily number of visitors.\n",
    "\n",
    "To do so, we can visualize the correlation matrix of the dataset, i.e. the correlation between each pair of features. The correlation matrix can be visualized using a heatmap, available in the `seaborn` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7ca8e6606955e562711f18118d3753c2",
     "grade": false,
     "grade_id": "cell-29fb1c2d3956d84c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Correlation matrix of the processed data\n",
    "correlation_matrix = data_processed.corr()\n",
    "plt.figure(figsize=(20, 20))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "53ce623e3fdf8e205e18d615cc33e613",
     "grade": false,
     "grade_id": "cell-b401a1133a38a28d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "This visualization is almost impossible to read when the number of features is large. Instead, we can focus on the correlation between the output variable `daily_visitors` and the other features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4f396fb3b1f5f2adc14b644039d840f1",
     "grade": false,
     "grade_id": "cell-e2553ae9666576b0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Correlation of the daily_visitors with the other features, by descending order\n",
    "correlation_daily_visitors = correlation_matrix['daily_visitors'].sort_values(ascending=False)\n",
    "correlation_daily_visitors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "91426da1ec3252e370f0fb309d7930f4",
     "grade": false,
     "grade_id": "cell-2147ea8ee7dea3d4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>Instruction:</b> What are the most correlated features with the number of daily visitors? Can you interpret this result?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "14e849658d03d1dd7c9713fc9ab2dc8a",
     "grade": false,
     "grade_id": "cell-6654e009db473f05",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Finally, we can split our dataset into an input matrix `X` and an output vector `y`, and then split `X`and `y` into training and testing sets: `(X_train, y_train)` and `(X_test, y_test)`.\n",
    "\n",
    "The training set is used to train the machine learning model, while the testing set is used to evaluate the model's performance on unseen data.\n",
    "\n",
    "It is common to split the dataset into 80% training and 20% testing data. We can use the `train_test_split` function from the `scikit-learn` library to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0e2caeda7328fa6cd6b9600e9f8bb82b",
     "grade": false,
     "grade_id": "cell-51c26da6094df92d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Split the data into X and y\n",
    "X = data_processed.iloc[:, :-1]\n",
    "y = data_processed.iloc[:, -1]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6d513c0883669f254be34ba32d4cb25e",
     "grade": false,
     "grade_id": "cell-22fdcaacd63af3e6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# 3. Model selection and definition\n",
    "\n",
    "To simplify the model selection step, we will only consider a mutli-layer perceptron (MLP) model. The MLP model is a type of artificial neural network that is commonly used for regression and classification tasks.\n",
    "\n",
    "The library `keras` provides an easy-to-use API to build and train neural networks. We will use the `Sequential` class from `keras` to build our MLP regressor.\n",
    "\n",
    "The architecture of the MLP model is defined by the number of layers, the number of neurons in each layer, and the activation function used in each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "46f53f8c5eb1c93501d3f68a9b3b7799",
     "grade": false,
     "grade_id": "cell-a7b53ecc67513d25",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "! pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "32eba536c716cd90ce067f045794c377",
     "grade": false,
     "grade_id": "cell-4bb57403f927fe6d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# MLP regressor using keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Create the model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e23bfa3af4ea197f57eae5f85d6afcac",
     "grade": false,
     "grade_id": "cell-ee6f67da4aaab0b5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# 4. Model training\n",
    "\n",
    "Now we chose and defined our machine learning model, we can train it on the training data `(X_train, y_train)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2d7c91fc91711154b86a96622de33f85",
     "grade": false,
     "grade_id": "cell-db479736b95cbd0b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='mean_squared_error', optimizer=Adam())\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=30, batch_size=30, validation_split=0.2, verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fbde479dce598499890663d5081d4ce8",
     "grade": false,
     "grade_id": "cell-f8d19c448b8f4bcb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>Instruction:</b> Plot the training and validation loss as a function of the number of epoch, using the `history` variable.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1defb08ed67a1d4bfe7ef63db24cfdc0",
     "grade": true,
     "grade_id": "cell-68704856e4c364c9",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b170e2231b94052e6397377c2b4a992c",
     "grade": true,
     "grade_id": "cell-909bc28d9173c53d",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>Instruction:</b> Describe and interpret the plot. What can you say about the model's performance?\n",
    "</div>\n",
    "\n",
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3c514d3b2e52ff20ceb75e806102e868",
     "grade": false,
     "grade_id": "cell-5876f6e4ea88655d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# 5. Model evaluation\n",
    "\n",
    "The model's performance has now to be evaluated on the unseen testing data `(X_test, y_test)` we preserved. \n",
    "\n",
    "Let's first oberse the real `y` values (ground truth) alongside the predicted `y_pred` values produced by our machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ed9ebd62e543c393153e96875d676fb8",
     "grade": false,
     "grade_id": "cell-9f19204da7725824",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Predict the daily visitor from the test set\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = y_pred.reshape(y_pred.shape[0])\n",
    "results = pd.DataFrame({'True': y_test, 'Predicted': y_pred})\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d5ba0d71e8474ef85bb9c7ca32b0749a",
     "grade": false,
     "grade_id": "cell-43ec4440035911bc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The most common metrics to evaluate a regression model are:\n",
    "\n",
    "- Mean absolute error (MAE)\n",
    "- Mean squared error (MSE)\n",
    "- R-squared\n",
    "- ...\n",
    "\n",
    "We will use the mean absolute error (MAE) to obtain a performance score of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "29cea2b7305dd912409367d064c391a0",
     "grade": false,
     "grade_id": "cell-dcdaf0b99c224369",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "msa = mean_absolute_error(y_test, y_pred)\n",
    "print(f'Mean absolute error on the test set: {msa}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b2f20fa137af14aac7fc4e8c7f5d18ce",
     "grade": false,
     "grade_id": "cell-764b1e462fb0824b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In the context of our problem of visitor prediction, the MAE represents the average absolute difference between the predicted number of visitors and the actual number of visitors.\n",
    "\n",
    "In other words, our model makes an average error of `N = MAE` visitors when predicting the number of visitors in the Bristol's museums."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e525229d1065c25d5b1d2dbbacdb4639",
     "grade": false,
     "grade_id": "cell-05bbe620183cb16e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# 6. Model prediction and deployment (for the brave!)\n",
    "\n",
    "We may have trained and evaluated a good machine learning model, but it remains useless if it is not deployed in a real-world scenario.\n",
    "\n",
    "For instance, how can we help workers in the Bristol museums to predict the number of visitors for the next week?\n",
    "\n",
    "To do so, we must develop meaningful interactions between users and the machine learning pipeline: the data, the model, and its predictions.\n",
    "\n",
    "[Marcelle](https://marcelle.dev/) is a modular open source toolkit for programming interactive machine learning applications. Marcelle is built around components embedding computation and interaction that can be composed to form reactive machine learning pipelines and custom user interfaces. This architecture enables rapid prototyping and extension. Marcelle can be used to build interfaces to Python scripts, and it provides flexible data stores to facilitate collaboration between machine learning experts, designers and end users.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<b>Instruction:</b> Use Marcelle to build an interactive application that predicts the number of visitors in the Bristol museums.\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
